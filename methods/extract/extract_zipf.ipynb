{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO verify that all these cross sections belong in Angus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import scraper\n",
    "import numpy as np\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "userHome = config.userHome()\n",
    "pdfHome = userHome + \"/projects/nepc/ref/angus/\"\n",
    "outdir = userHome + \"/projects/nepc/data/formatted/n2/zipf/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: /home/adamson//projects/nepc/data/formatted/n2/zipf/ - No such file or directory.\n"
     ]
    }
   ],
   "source": [
    "scraper.rmdir(outdir)\n",
    "scraper.mkdir(outdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfZipf = scraper.getPDF(pdfHome + \"20_zipf_et_al-1980-Journal_of_Geophysical_Research__Space_Physics.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = []\n",
    "filenames.append(outdir + 'd_ionization_N2_4S_zipf')\n",
    "filenames.append(outdir + 'd_ionization_N2_2D_zipf')\n",
    "filenames.append(outdir + 'dissociation_N2_4S_2D_zipf')\n",
    "filenames.append(outdir + 'dissociation_N2_2D_2D_zipf')\n",
    "filenames.append(outdir + 'dissociation_N2_4S_2P_zipf')\n",
    "filenames.append(outdir + 'd_ionization_N2_total_zipf')\n",
    "filenames.append(outdir + 'dissociation_N2_total_zipf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropDimX = [120, 150, 180, 480]\n",
    "cropDimY = []\n",
    "cropDimY.append([180, 170, 240, 480])\n",
    "cropDimY.append([240, 295, 300, 480])\n",
    "cropDimY.append([300, 170, 350, 480])\n",
    "cropDimY.append([350, 190, 410, 480])\n",
    "cropDimY.append([410, 150, 470, 480])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "background = '''in situ study of the excitation and collisional deactivation of N(2p) atoms in an IBC II + aurora. The N(2p)  concentration and altitude distribution from 110 to 195 km was determined from measurements of the intensity of the NI(4S - 2p;lambda=3466 Angstrom) doublet. The optical data were obtained by a filtered photometer onboard a  Taurus-Orion sounding rocket (33.001 UA) that was launched into a bright auroral arc. Complementary measurements of the  intensity of the (0, 0) first negative band of N2+[lambda=3914 Angstrom] and of the flux and energy distribution of the precipitating electrons in the  0-500 eV energy range were also made.'''\n",
    "metadata= []\n",
    "metadata.append({\n",
    "    \"specie\":\"N2\",\n",
    "    \"process\":\"d_ionization\",\n",
    "    \"lhsA\":\"N2(X1Sigmag+)\",\n",
    "    \"rhsA\":\"N+(2s22p2 3P0)\",\n",
    "    \"rhsB\":\"N(2s22p3 4So)\",\n",
    "    \"units_e\":1.0,\n",
    "    \"units_sigma\":1.0E-4,\n",
    "    \"ref\":\"zipf1980\",\n",
    "    \"background\":background + '''  Dissociative ionization channel results in equal probability of 4S and 2D N states, so data for taken from column [3] of Table 3.'''})\n",
    "metadata.append({\n",
    "    \"specie\":\"N2\",\n",
    "    \"process\":\"d_ionization\",\n",
    "    \"lhsA\":\"N2(X1Sigmag+)\",\n",
    "    \"rhsA\":\"N+(2s22p2 3P0)\",\n",
    "    \"rhsB\":\"N(2s22p3 2Do)\",\n",
    "    \"units_e\":1.0,\n",
    "    \"units_sigma\":1.0E-4,\n",
    "    \"ref\":\"zipf1980\",\n",
    "    \"background\":background + '''  Data taken from column [3] of Table 3.'''})\n",
    "metadata.append({\n",
    "    \"specie\":\"N2\",\n",
    "    \"process\":\"dissociation\",\n",
    "    \"lhsA\":\"N2(X1Sigmag+)\",\n",
    "    \"rhsA\":\"N(2s22p3 4So)\",\n",
    "    \"rhsB\":\"N(2s22p3 2Do)\",\n",
    "    \"units_e\":1.0,\n",
    "    \"units_sigma\":1.0E-4,\n",
    "    \"ref\":\"zipf1980\",\n",
    "    \"background\":background + '''  This channel is one of two N2 singlet state predissociation pathways. We make the assumption that 85% of N2 singlet states dissociate into a N(4S) and N(2D) pair. Since the values in Table 3 are specific cross sections, the cross sections for this process are computed as 74% of Table 3 column [2].'''})\n",
    "metadata.append({\n",
    "    \"specie\":\"N2\",\n",
    "    \"process\":\"dissociation\",\n",
    "    \"lhsA\":\"N2(X1Sigmag+)\",\n",
    "    \"rhsA\":\"N(2s22p3 2Do)\",\n",
    "    \"rhsB\":\"N(2s22p3 2Do)\",\n",
    "    \"units_e\":1.0,\n",
    "    \"units_sigma\":1.0E-4,\n",
    "    \"ref\":\"zipf1980\",\n",
    "    \"background\":background + '''  This channel is one of two N2 singlet state predissociation pathways. We make the assumption that 15% of N2 singlet states dissociate into a N(2D) pair. Since the values in Table 3 are specific cross sections, the cross sections for this process are computed as 26% of Table 3 column [2].'''})\n",
    "metadata.append({\n",
    "    \"specie\":\"N2\",\n",
    "    \"process\":\"dissociation\",\n",
    "    \"lhsA\":\"N2(X1Sigmag+)\",\n",
    "    \"rhsA\":\"N(2s22p3 4So)\",\n",
    "    \"rhsB\":\"N(2s22p3 2Po)\",\n",
    "    \"units_e\":1.0,\n",
    "    \"units_sigma\":1.0E-4,\n",
    "    \"ref\":\"zipf1980\",\n",
    "    \"background\":background + '''  Data taken directly from column [5] of Table 3'''})\n",
    "metadata.append({\n",
    "    \"specie\":\"N2\",\n",
    "    \"process\":\"d_ionization_total\",\n",
    "    \"lhsA\":\"N2(X1Sigmag+)\",\n",
    "    \"rhsA\":\"N+\",\n",
    "    \"rhsB\":\"N\",\n",
    "    \"units_e\":1.0,\n",
    "    \"units_sigma\":1.0E-4,\n",
    "    \"ref\":\"zipf1980\",\n",
    "    \"background\":background + '''  Data taken from column [3] of Table 3.  Multiply values in table by 2 since there is equal probability of 4S and 2D N states.'''})\n",
    "metadata.append({\n",
    "    \"specie\":\"N2\",\n",
    "    \"process\":\"dissociation_total\",\n",
    "    \"lhsA\":\"N2\",\n",
    "    \"rhsA\":\"N\",\n",
    "    \"rhsB\":\"N\",\n",
    "    \"units_e\":1.0,\n",
    "    \"units_sigma\":1.0E-4,\n",
    "    \"ref\":\"zipf1980\",\n",
    "    \"background\":background + '''  Values determined by adding columns [2] and [5] from Table 3'''})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataX = scraper.getColumnStrings(pdf=pdfZipf,pageNumber=6,cropDimArray=cropDimX,locateTables=False)\n",
    "dataX = scraper.textArrayToFloatArray(dataX)\n",
    "dataSigma = []\n",
    "for i in range(len(cropDimY)):\n",
    "    dataY = scraper.getColumnStrings(pdf=pdfZipf,pageNumber=6,cropDimArray=cropDimY[i],locateTables=False)\n",
    "    dataY=[s.replace('(', 'E') for s in dataY]\n",
    "    dataY=[s.replace(')', '') for s in dataY]\n",
    "    dataY=[s.replace('t', '') for s in dataY]\n",
    "    dataY=[s.replace(',', '.') for s in dataY]\n",
    "    dataY=[s.replace(' ', '') for s in dataY]\n",
    "    dataY=scraper.textArrayToFloatArray(dataY)\n",
    "    \n",
    "    N=len(dataX)-len(dataY)\n",
    "    for j in range(N):\n",
    "        dataY=np.concatenate(([[0]],dataY),axis=0)\n",
    "    \n",
    "    dataSigma.append(dataY)\n",
    "            \n",
    "'''Table 3, column 2 (dataSigma[0]); Table 3, column 3 (dataSigma[1]), etc'''\n",
    "for i in range(len(metadata)):\n",
    "    \n",
    "    if i==0:\n",
    "        data = np.concatenate((dataX, dataSigma[1]),axis=1)\n",
    "    if i==1:\n",
    "        data = np.concatenate((dataX, dataSigma[1]),axis=1)\n",
    "    if i==2:\n",
    "        data = np.concatenate((dataX, 0.74*dataSigma[0]),axis=1)\n",
    "    if i==3:\n",
    "        data = np.concatenate((dataX, 0.26*dataSigma[0]),axis=1)\n",
    "    if i==4:\n",
    "        data = np.concatenate((dataX, dataSigma[3]),axis=1)\n",
    "    if i==5:\n",
    "        data = np.concatenate((dataX, 2.0*dataSigma[1]),axis=1)\n",
    "    if i==6:\n",
    "        data = np.concatenate((dataX, dataSigma[0]+dataSigma[3]),axis=1)\n",
    "    \n",
    "    scraper.writeDataToFile(data,filenames[i]+\".dat\")\n",
    "    scraper.writeMetaDataToFile(filename=filenames[i]+\".met\",\n",
    "                                specie=metadata[i][\"specie\"],\n",
    "                                process=metadata[i]['process'],\n",
    "                                lhsA=metadata[i]['lhsA'],\n",
    "                                rhsA=metadata[i]['rhsA'],\n",
    "                                rhsB=metadata[i]['rhsB'],\n",
    "                                units_e=metadata[i]['units_e'],\n",
    "                                units_sigma=metadata[i]['units_sigma'],\n",
    "                                ref=metadata[i]['ref'],\n",
    "                                background=metadata[i]['background'])\n",
    "    scraper.writeModelsToFile(filename=filenames[i]+\".mod\",\n",
    "                              modelsArray=[\"angus\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
