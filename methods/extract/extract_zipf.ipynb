{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO verify that all these cross sections belong in Angus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nepc.util import config\n",
    "from nepc.util import scraper\n",
    "import pdfplumber\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEPC_HOME = config.nepc_home()\n",
    "pdfHome = NEPC_HOME + \"/ref/angus/\"\n",
    "outdir = NEPC_HOME + \"/data/formatted/n2/zipf/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraper.rmdir(outdir)\n",
    "scraper.mkdir(outdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfZipf = scraper.getPDF(pdfHome + \"20_zipf_et_al-1980-Journal_of_Geophysical_Research__Space_Physics.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = []\n",
    "filenames.append(outdir + 'd_ionization_N2_4S_zipf')\n",
    "filenames.append(outdir + 'd_ionization_N2_2D_zipf')\n",
    "filenames.append(outdir + 'dissociation_N2_4S_2D_zipf')\n",
    "filenames.append(outdir + 'dissociation_N2_2D_2D_zipf')\n",
    "filenames.append(outdir + 'dissociation_N2_4S_2P_zipf')\n",
    "filenames.append(outdir + 'd_ionization_N2_total_zipf')\n",
    "filenames.append(outdir + 'dissociation_N2_total_zipf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_states_file = NEPC_HOME + \"/mysql/n_states.tsv\"\n",
    "np_states_file = NEPC_HOME + \"/mysql/n+_states.tsv\"\n",
    "n2_states_file = NEPC_HOME + \"/mysql/n2_states.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "(n_states, n_states_long) = scraper.get_states(n_states_file)\n",
    "(np_states, np_states_long) = scraper.get_states(np_states_file)\n",
    "(n2_states, n2_states_long) = scraper.get_states(n2_states_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['N',\n",
       " 'N_2s22p3_4So',\n",
       " 'N_2s22p3_2Do',\n",
       " 'N_2s22p3_2Po',\n",
       " 'N_2s22p2_3P_3s_4P',\n",
       " 'N_2s22p2_3P_3s_2P',\n",
       " 'N_2s22p4_4P',\n",
       " 'N_2s22p2_3P_3p_2So',\n",
       " 'N_2s22p2_3P_3p_4Do',\n",
       " 'N_2s22p2_3P_3p_4Po',\n",
       " 'N_2s22p2_3P_3p_4So',\n",
       " 'N_2s22p2_3P_3p_2Do',\n",
       " 'N_2s22p2_3P_3p_2Po',\n",
       " 'N_2s22p2_1D_3s_2D',\n",
       " 'N_2s22p2_3P_4s_4P',\n",
       " 'N_2s22p2_3P_4s_2P',\n",
       " 'N_2s22p2_3P_3d_2P',\n",
       " 'N_2s22p2_3P_3d_4F',\n",
       " 'N_2s22p2_3P_3d_4P',\n",
       " 'N_2s22p2_3P_3d_2F',\n",
       " 'N_2s22p2_3P_3d_4D',\n",
       " 'N_2s22p2_3P_3d_2D',\n",
       " 'N_2s22p2_3P_4p_2So',\n",
       " 'N_2s22p2_3P_4p_4Do',\n",
       " 'N_2s22p2_3P_4p_4Po',\n",
       " 'N_2s22p2_3P_4p_2Do',\n",
       " 'N_2s22p2_3P_4p_4So',\n",
       " 'N_2s22p2_3P_4p_2Po']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['N+', 'N+_2s22p2_3P', 'N+_2s12p3_1D', 'N+_2s12p3_1S']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['N2',\n",
       " 'N2(X1Sigmag+)',\n",
       " 'N2(A3Sigmau+)',\n",
       " 'N2(B3Pig)',\n",
       " 'N2(W3Deltau)',\n",
       " 'N2(Bp3Sigmau-)',\n",
       " 'N2(ap1Sigmau-)',\n",
       " 'N2(a1Pig)',\n",
       " 'N2(w1Deltau)',\n",
       " 'N2(C3Piu)',\n",
       " 'N2(E3Sigmag+)',\n",
       " 'N2(app1Sigmag+)',\n",
       " 'N2(c4p1Sigmau+)']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n2_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropDimX = [120, 150, 180, 480]\n",
    "cropDimY = []\n",
    "cropDimY.append([180, 170, 240, 480])\n",
    "cropDimY.append([240, 295, 300, 480])\n",
    "cropDimY.append([300, 170, 350, 480])\n",
    "cropDimY.append([350, 190, 410, 480])\n",
    "cropDimY.append([410, 150, 470, 480])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "background = '''in situ study of the excitation and collisional deactivation of N(2p) atoms in an IBC II + aurora. The N(2p)  concentration and altitude distribution from 110 to 195 km was determined from measurements of the intensity of the NI(4S - 2p;lambda=3466 Angstrom) doublet. The optical data were obtained by a filtered photometer onboard a  Taurus-Orion sounding rocket (33.001 UA) that was launched into a bright auroral arc. Complementary measurements of the  intensity of the (0, 0) first negative band of N2+[lambda=3914 Angstrom] and of the flux and energy distribution of the precipitating electrons in the  0-500 eV energy range were also made.'''\n",
    "metadata= []\n",
    "metadata.append({\n",
    "    \"specie\":\"N2\",\n",
    "    \"process\":\"d_ionization_partial\",\n",
    "    \"lhsA\":n2_states[1],\n",
    "    \"rhsA\":np_states[1],\n",
    "    \"rhsB\":n_states[1],\n",
    "    \"units_e\":1.0,\n",
    "    \"units_sigma\":1.0E-4,\n",
    "    \"ref\":\"zipf1980\",\n",
    "    \"background\":background + '''  Dissociative ionization channel results in equal probability of 4S and 2D N states, so data for taken from column [3] of Table 3.'''})\n",
    "metadata.append({\n",
    "    \"specie\":\"N2\",\n",
    "    \"process\":\"d_ionization_partial\",\n",
    "    \"lhsA\":n2_states[1],\n",
    "    \"rhsA\":np_states[1],\n",
    "    \"rhsB\":n_states[2],\n",
    "    \"units_e\":1.0,\n",
    "    \"units_sigma\":1.0E-4,\n",
    "    \"ref\":\"zipf1980\",\n",
    "    \"background\":background + '''  Data taken from column [3] of Table 3.'''})\n",
    "metadata.append({\n",
    "    \"specie\":\"N2\",\n",
    "    \"process\":\"dissociation_partial\",\n",
    "    \"lhsA\":n2_states[1],\n",
    "    \"rhsA\":n_states[1],\n",
    "    \"rhsB\":n_states[2],\n",
    "    \"units_e\":1.0,\n",
    "    \"units_sigma\":1.0E-4,\n",
    "    \"ref\":\"zipf1980\",\n",
    "    \"background\":background + '''  This channel is one of two N2 singlet state predissociation pathways. We make the assumption that 85% of N2 singlet states dissociate into a N(4S) and N(2D) pair. Since the values in Table 3 are specific cross sections, the cross sections for this process are computed as 74% of Table 3 column [2].'''})\n",
    "metadata.append({\n",
    "    \"specie\":\"N2\",\n",
    "    \"process\":\"dissociation_partial\",\n",
    "    \"lhsA\":n2_states[1],\n",
    "    \"rhsA\":n_states[2],\n",
    "    \"rhsB\":n_states[2],\n",
    "    \"units_e\":1.0,\n",
    "    \"units_sigma\":1.0E-4,\n",
    "    \"ref\":\"zipf1980\",\n",
    "    \"background\":background + '''  This channel is one of two N2 singlet state predissociation pathways. We make the assumption that 15% of N2 singlet states dissociate into a N(2D) pair. Since the values in Table 3 are specific cross sections, the cross sections for this process are computed as 26% of Table 3 column [2].'''})\n",
    "metadata.append({\n",
    "    \"specie\":\"N2\",\n",
    "    \"process\":\"dissociation_partial\",\n",
    "    \"lhsA\":n2_states[1],\n",
    "    \"rhsA\":n_states[1],\n",
    "    \"rhsB\":n_states[3],\n",
    "    \"units_e\":1.0,\n",
    "    \"units_sigma\":1.0E-4,\n",
    "    \"ref\":\"zipf1980\",\n",
    "    \"background\":background + '''  Data taken directly from column [5] of Table 3'''})\n",
    "metadata.append({\n",
    "    \"specie\":\"N2\",\n",
    "    \"process\":\"d_ionization\",\n",
    "    \"lhsA\":n2_states[1],\n",
    "    \"rhsA\":np_states[0],\n",
    "    \"rhsB\":n_states[0],\n",
    "    \"units_e\":1.0,\n",
    "    \"units_sigma\":1.0E-4,\n",
    "    \"ref\":\"zipf1980\",\n",
    "    \"background\":background + '''  Data taken from column [3] of Table 3.  Multiply values in table by 2 since there is equal probability of 4S and 2D N states.'''})\n",
    "metadata.append({\n",
    "    \"specie\":\"N2\",\n",
    "    \"process\":\"dissociation\",\n",
    "    \"lhsA\":n2_states[0],\n",
    "    \"rhsA\":n_states[0],\n",
    "    \"rhsB\":n_states[0],\n",
    "    \"units_e\":1.0,\n",
    "    \"units_sigma\":1.0E-4,\n",
    "    \"ref\":\"zipf1980\",\n",
    "    \"background\":background + '''  Values determined by adding columns [2] and [5] from Table 3'''})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataX = scraper.getColumnStrings(pdf=pdfZipf,pageNumber=6,cropDimArray=cropDimX,locateTables=False)\n",
    "dataX = scraper.textArrayToFloatArray(dataX)\n",
    "dataSigma = []\n",
    "for i in range(len(cropDimY)):\n",
    "    dataY = scraper.getColumnStrings(pdf=pdfZipf,pageNumber=6,cropDimArray=cropDimY[i],locateTables=False)\n",
    "    dataY=[s.replace('(', 'E') for s in dataY]\n",
    "    dataY=[s.replace(')', '') for s in dataY]\n",
    "    dataY=[s.replace('t', '') for s in dataY]\n",
    "    dataY=[s.replace(',', '.') for s in dataY]\n",
    "    dataY=[s.replace(' ', '') for s in dataY]\n",
    "    dataY=scraper.textArrayToFloatArray(dataY)\n",
    "    \n",
    "    N=len(dataX)-len(dataY)\n",
    "    for j in range(N):\n",
    "        dataY=np.concatenate(([[0]],dataY),axis=0)\n",
    "    \n",
    "    dataSigma.append(dataY)\n",
    "            \n",
    "'''Table 3, column 2 (dataSigma[0]); Table 3, column 3 (dataSigma[1]), etc'''\n",
    "for i in range(len(metadata)):\n",
    "    \n",
    "    if i==0:\n",
    "        data = np.concatenate((dataX, dataSigma[1]),axis=1)\n",
    "    if i==1:\n",
    "        data = np.concatenate((dataX, dataSigma[1]),axis=1)\n",
    "    if i==2:\n",
    "        data = np.concatenate((dataX, 0.74*dataSigma[0]),axis=1)\n",
    "    if i==3:\n",
    "        data = np.concatenate((dataX, 0.26*dataSigma[0]),axis=1)\n",
    "    if i==4:\n",
    "        data = np.concatenate((dataX, dataSigma[3]),axis=1)\n",
    "    if i==5:\n",
    "        data = np.concatenate((dataX, 2.0*dataSigma[1]),axis=1)\n",
    "    if i==6:\n",
    "        data = np.concatenate((dataX, dataSigma[0]+dataSigma[3]),axis=1)\n",
    "    \n",
    "    scraper.writeDataToFile(data,filenames[i]+\".dat\")\n",
    "    scraper.writeMetaDataToFile(filename=filenames[i]+\".met\",\n",
    "                                specie=metadata[i][\"specie\"],\n",
    "                                process=metadata[i]['process'],\n",
    "                                lhsA=metadata[i]['lhsA'],\n",
    "                                rhsA=metadata[i]['rhsA'],\n",
    "                                rhsB=metadata[i]['rhsB'],\n",
    "                                units_e=metadata[i]['units_e'],\n",
    "                                units_sigma=metadata[i]['units_sigma'],\n",
    "                                ref=metadata[i]['ref'],\n",
    "                                background=metadata[i]['background'])\n",
    "    scraper.writeModelsToFile(filename=filenames[i]+\".mod\",\n",
    "                              modelsArray=[\"angus\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
