{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO verify that all these cross sections belong in Angus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nepc.util import config\n",
    "from nepc.util import scraper\n",
    "import pdfplumber\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEPC_HOME = config.nepc_home()\n",
    "pdfHome = NEPC_HOME + \"/ref/angus/\"\n",
    "outdir = NEPC_HOME + \"/data/cs/n2/zipf/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraper.rmdir(outdir)\n",
    "scraper.mkdir(outdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfZipf = scraper.get_pdf(pdfHome + \"20_zipf_et_al-1980-Journal_of_Geophysical_Research__Space_Physics.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = []\n",
    "filenames.append(outdir + 'd_ionization_N2_4S_zipf')\n",
    "filenames.append(outdir + 'd_ionization_N2_2D_zipf')\n",
    "filenames.append(outdir + 'dissociation_N2_4S_2D_zipf')\n",
    "filenames.append(outdir + 'dissociation_N2_2D_2D_zipf')\n",
    "filenames.append(outdir + 'dissociation_N2_4S_2P_zipf')\n",
    "filenames.append(outdir + 'd_ionization_N2_total_zipf')\n",
    "filenames.append(outdir + 'dissociation_N2_total_zipf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_cs_id, next_csdata_id = scraper.get_next_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "418"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_cs_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "202016"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_csdata_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropDimX = [120, 150, 180, 480]\n",
    "cropDimY = []\n",
    "cropDimY.append([180, 170, 240, 480])\n",
    "cropDimY.append([240, 295, 300, 480])\n",
    "cropDimY.append([300, 170, 350, 480])\n",
    "cropDimY.append([350, 190, 410, 480])\n",
    "cropDimY.append([410, 150, 470, 480])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "background = '''in situ study of the excitation and collisional deactivation of N(2p) atoms in an IBC II + aurora. The N(2p)  concentration and altitude distribution from 110 to 195 km was determined from measurements of the intensity of the NI(4S - 2p;lambda=3466 Angstrom) doublet. The optical data were obtained by a filtered photometer onboard a  Taurus-Orion sounding rocket (33.001 UA) that was launched into a bright auroral arc. Complementary measurements of the  intensity of the (0, 0) first negative band of N2+[lambda=3914 Angstrom] and of the flux and energy distribution of the precipitating electrons in the  0-500 eV energy range were also made.'''\n",
    "metadata= []\n",
    "metadata.append({\n",
    "    \"specie\":\"N2\",\n",
    "    \"process\":\"d_ionization_partial\",\n",
    "    \"lhsA\":'N2(X1Sigmag+)',\n",
    "    \"rhsA\":'N+_2s22p2_3P',\n",
    "    \"rhsB\":'N_2s22p3_4So',\n",
    "    \"units_e\":1.0,\n",
    "    \"units_sigma\":1.0E-4,\n",
    "    \"ref\":\"zipf1980\",\n",
    "    \"background\":background + '''  Dissociative ionization channel results in equal probability of 4S and 2D N states, so data for taken from column [3] of Table 3. Assume N2 and N+ ground states.'''})\n",
    "metadata.append({\n",
    "    \"specie\":\"N2\",\n",
    "    \"process\":\"d_ionization_partial\",\n",
    "    \"lhsA\":'N2(X1Sigmag+)',\n",
    "    \"rhsA\":'N+_2s22p2_3P',\n",
    "    \"rhsB\":'N_2s22p3_2Do',\n",
    "    \"units_e\":1.0,\n",
    "    \"units_sigma\":1.0E-4,\n",
    "    \"ref\":\"zipf1980\",\n",
    "    \"background\":background + '''  Data taken from column [3] of Table 3. Assume N2 and N+ ground states.'''})\n",
    "metadata.append({\n",
    "    \"specie\":\"N2\",\n",
    "    \"process\":\"dissociation_partial\",\n",
    "    \"lhsA\":'N2(X1Sigmag+)',\n",
    "    \"rhsA\":'N_2s22p3_4So',\n",
    "    \"rhsB\":'N_2s22p3_2Do',\n",
    "    \"units_e\":1.0,\n",
    "    \"units_sigma\":1.0E-4,\n",
    "    \"ref\":\"zipf1980\",\n",
    "    \"background\":background + '''  This channel is one of two N2 singlet state predissociation pathways. We make the assumption that 85% of N2 singlet states dissociate into a N(4S) and N(2D) pair. Since the values in Table 3 are specific cross sections, the cross sections for this process are computed as 74% of Table 3 column [2]. Assue N2 ground state.'''})\n",
    "metadata.append({\n",
    "    \"specie\":\"N2\",\n",
    "    \"process\":\"dissociation_partial\",\n",
    "    \"lhsA\":'N2(X1Sigmag+)',\n",
    "    \"rhsA\":'N_2s22p3_2Do',\n",
    "    \"rhsB\":'N_2s22p3_2Do',\n",
    "    \"units_e\":1.0,\n",
    "    \"units_sigma\":1.0E-4,\n",
    "    \"ref\":\"zipf1980\",\n",
    "    \"background\":background + '''  This channel is one of two N2 singlet state predissociation pathways. We make the assumption that 15% of N2 singlet states dissociate into a N(2D) pair. Since the values in Table 3 are specific cross sections, the cross sections for this process are computed as 26% of Table 3 column [2].'''})\n",
    "metadata.append({\n",
    "    \"specie\":\"N2\",\n",
    "    \"process\":\"dissociation_partial\",\n",
    "    \"lhsA\":'N2(X1Sigmag+)',\n",
    "    \"rhsA\":'N_2s22p3_4So',\n",
    "    \"rhsB\":'N_2s22p3_2Po',\n",
    "    \"units_e\":1.0,\n",
    "    \"units_sigma\":1.0E-4,\n",
    "    \"ref\":\"zipf1980\",\n",
    "    \"background\":background + '''  Data taken directly from column [5] of Table 3'''})\n",
    "metadata.append({\n",
    "    \"specie\":\"N2\",\n",
    "    \"process\":\"d_ionization\",\n",
    "    \"lhsA\":'N2',\n",
    "    \"rhsA\":'N+',\n",
    "    \"rhsB\":'N',\n",
    "    \"units_e\":1.0,\n",
    "    \"units_sigma\":1.0E-4,\n",
    "    \"ref\":\"zipf1980\",\n",
    "    \"background\":background + '''  Data taken from column [3] of Table 3.  Multiply values in table by 2 since there is equal probability of 4S and 2D N states.'''})\n",
    "metadata.append({\n",
    "    \"specie\":\"N2\",\n",
    "    \"process\":\"dissociation\",\n",
    "    \"lhsA\":'N2',\n",
    "    \"rhsA\":'N',\n",
    "    \"rhsB\":'N',\n",
    "    \"units_e\":1.0,\n",
    "    \"units_sigma\":1.0E-4,\n",
    "    \"ref\":\"zipf1980\",\n",
    "    \"background\":background + '''  Values determined by adding columns [2] and [5] from Table 3'''})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataX = scraper.get_column_strings(pdf=pdfZipf,page_number=6,crop_dim_array=cropDimX,locate_tables=False)\n",
    "dataX = scraper.text_array_to_float_array(dataX)\n",
    "dataSigma = []\n",
    "for i in range(len(cropDimY)):\n",
    "    dataY = scraper.get_column_strings(pdf=pdfZipf,page_number=6,crop_dim_array=cropDimY[i],locate_tables=False)\n",
    "    dataY=[s.replace('(', 'E') for s in dataY]\n",
    "    dataY=[s.replace(')', '') for s in dataY]\n",
    "    dataY=[s.replace('t', '') for s in dataY]\n",
    "    dataY=[s.replace(',', '.') for s in dataY]\n",
    "    dataY=[s.replace(' ', '') for s in dataY]\n",
    "    dataY=scraper.text_array_to_float_array(dataY)\n",
    "    \n",
    "    N=len(dataX)-len(dataY)\n",
    "    for j in range(N):\n",
    "        dataY=np.concatenate(([[0]],dataY),axis=0)\n",
    "    \n",
    "    dataSigma.append(dataY)\n",
    "            \n",
    "'''Table 3, column 2 (dataSigma[0]); Table 3, column 3 (dataSigma[1]), etc'''\n",
    "for i in range(len(metadata)):\n",
    "    \n",
    "    if i==0:\n",
    "        data = np.concatenate((dataX, dataSigma[1]),axis=1)\n",
    "    if i==1:\n",
    "        data = np.concatenate((dataX, dataSigma[1]),axis=1)\n",
    "    if i==2:\n",
    "        data = np.concatenate((dataX, 0.74*dataSigma[0]),axis=1)\n",
    "    if i==3:\n",
    "        data = np.concatenate((dataX, 0.26*dataSigma[0]),axis=1)\n",
    "    if i==4:\n",
    "        data = np.concatenate((dataX, dataSigma[3]),axis=1)\n",
    "    if i==5:\n",
    "        data = np.concatenate((dataX, 2.0*dataSigma[1]),axis=1)\n",
    "    if i==6:\n",
    "        data = np.concatenate((dataX, dataSigma[0]+dataSigma[3]),axis=1)\n",
    "    \n",
    "    next_csdata_id = scraper.write_data_to_file(data,\n",
    "                                                filenames[i]+\".dat\",\n",
    "                                                start_csdata_id=next_csdata_id)\n",
    "    next_cs_id = scraper.write_metadata_to_file(filename=filenames[i]+\".met\",\n",
    "                                                cs_id=next_cs_id,\n",
    "                                specie=metadata[i][\"specie\"],\n",
    "                                process=metadata[i]['process'],\n",
    "                                lhs_a=metadata[i]['lhsA'],\n",
    "                                rhs_a=metadata[i]['rhsA'],\n",
    "                                rhs_b=metadata[i]['rhsB'],\n",
    "                                units_e=metadata[i]['units_e'],\n",
    "                                units_sigma=metadata[i]['units_sigma'],\n",
    "                                ref=metadata[i]['ref'],\n",
    "                                background=metadata[i]['background'])\n",
    "    scraper.write_models_to_file(filename=filenames[i]+\".mod\",\n",
    "                              models_array=[\"angus\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraper.write_next_id_to_file(next_cs_id, next_csdata_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
